{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Audit and Mitigate Bias in Machine Learning Models to Improve Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement**:  We are tasked with building a model that can predict whether or not an individual will default on their loan, based on a loan application they have submitted that contains the features listed above.\n",
    "\n",
    "In practice, the firm has enough resources to review and approve 75% of the applications that are submitted, therefore, they would like to identify the 25% highest risk applications so that they may be either automatically rejected, or perhaps only reviewed if time allows.\n",
    "\n",
    "The dataset for this notebook comes from the Kaggle dataset \"Loan Default Model Trap\" (https://www.kaggle.com/jannesklaas/model-trap/version/5).\n",
    "\n",
    "**Features**\n",
    "- Minority - 1/0 (1 == Black, 0 == White)\n",
    "- Sex - 1/0 (1 == Male, 0 == Female)\n",
    "- ZIP code - categorical\n",
    "- Rent - 1/0\n",
    "- Age - continuous\n",
    "- Education - continuous\n",
    "- Income - continuous\n",
    "- Loan_size - continuous\n",
    "- Payment timing - continuous\n",
    "- year - discrete, ordinal\n",
    "- Job stability - continuous\n",
    "- Occupation - categorical\n",
    "\n",
    "**Target**\n",
    "- Default on loan - True / False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import make_scorer,confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"data/train.csv\")\n",
    "test_raw = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_raw.shape)\n",
    "train_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_raw.shape)\n",
    "test_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(data):\n",
    "    # The variables minority, sex, rent, education, age,i ncome, loan_size, payment_timing, job_stability, year\n",
    "    #   are continuous\n",
    "    X = data.filter(items=['minority','sex','rent','education','age','income','loan_size','payment_timing','job_stability','year'])\n",
    "    # ZIP and occupation must be one-hot encoded\n",
    "    zip_one_hot = pd.get_dummies(data['ZIP'],drop_first=True)\n",
    "    X = pd.merge(X,zip_one_hot.add_suffix('_zip'), how='left',left_index=True, right_index=True)\n",
    "    occupation_one_hot = pd.get_dummies(data['occupation'],drop_first=True)\n",
    "    X = pd.merge(X,occupation_one_hot.add_suffix('_occupation'), how='left',left_index=True, right_index=True)\n",
    "    \n",
    "    # Target will be recode as 1 for True, 0 for False\n",
    "    y = data['default'].apply(lambda x: 1 if x else 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = transformer(train_raw)\n",
    "X_test, y_test = transformer(test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train a logistic regresion model and use a simple grid search (parameter grid can be seen in the code box below on line 7).\n",
    "\n",
    "For evaluation, it's important that we choose the right metric.  Consider the possible outcomes of our model, given that the intervention automatically denies anyone who is in the top 25% highest predicted scores to default:\n",
    "\n",
    "- **True positive:**  the model said they would default, and they did\n",
    "- **False positive:**  the model said they would default, and they didn't\n",
    "- **True negative:**  the model says they would not default, and they wouldn't\n",
    "- **False negative:**  the model says they would not default, and they would\n",
    "\n",
    "Clearly, we want to maximize **True Positives**.  When we consider our two errors, which is more costly?  Arugably, it is the **False Negative**.\n",
    "\n",
    "Therefore, it makes sense to use a performance metric, that when the model has many **True Positives** will be high, but that will be penalized for haing too many **False Negatives**.  Reference for performance metrics:  https://en.wikipedia.org/wiki/Precision_and_recall.\n",
    "\n",
    "As a result, we can choose to look to the performance metric recall (also called sensitivity or hit rate), for which the formula is\n",
    "- **TP / (TP + FN)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "print(\"Penalty      C         Recall Score\")\n",
    "print(\"-----------------------------------\")\n",
    "best_recall = 0\n",
    "\n",
    "# Create the parameter grid and iterate through\n",
    "grid = [[x,y] for x in ['l1','l2'] for y in [1.00,0.10,0.01]]\n",
    "for Penalty,c in grid:    \n",
    "    \n",
    "    print(f\"{Penalty}           {c:.2f}      Training...\", end=\"\\r\")\n",
    "    \n",
    "    # Train a model with the current grid parameters and evaluate the recall score\n",
    "    temp_model = LogisticRegression(penalty=Penalty,C=c,solver='liblinear',random_state=42).fit(X_train,y_train)\n",
    "    temp_y_pred_proba = temp_model.predict_proba(X_test)[:,1]\n",
    "    temp_threshold = np.percentile(temp_y_pred_proba,75)\n",
    "    temp_y_pred = np.where(temp_y_pred_proba > temp_threshold, 1, 0)\n",
    "    temp_recall = recall_score(y_test,temp_y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"{Penalty}           {c:.2f}      {temp_recall}\")\n",
    "    \n",
    "    # If this is the best performing model, save the results\n",
    "    if temp_recall > best_recall:\n",
    "        best_recall = temp_recall\n",
    "        model = temp_model\n",
    "        y_pred = temp_y_pred\n",
    "\n",
    "# Scikit-learn GridSearchCV implementaiton\n",
    "# -------------------------------------------\n",
    "# recall_scorer = make_scorer(recall_score)\n",
    "# grid = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid={'C': [1, 0.1, 0.01],'penalty':['l1','l2']},scoring=recall_scorer)\n",
    "# results = grid.fit(X_train,y_train)\n",
    "# model = grid.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "categories = ['Comply','Default']\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues',xticklabels=categories,yticklabels=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a naÃ¯ve approach to evaluating bias, we will apply methods for explainability and interpretability.  For a logistic regression, this means examining the feature importance, or the coefficeint weight of each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(X_train.columns, model.coef_[0], color='b')\n",
    "plt.tight_layout(-10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will conduct a robust bias audit using the tooklit Aequitas.\n",
    "\n",
    "This code is a shortened version of the highly recommended Aequitas COMPAS Analysis demo (https://dssg.github.io/aequitas/examples/compas_demo.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a metric\n",
    "\n",
    "Consider the context of the problem, and how we may want to think about fairness (consider the \"Fairness Tree\" from this reference: http://www.datasciencepublicpolicy.org/projects/aequitas/).\n",
    "\n",
    "In this case, because our intervention is punitive, and we are intervening on a large portion of the population, the Fairness Tree guides us towards choosing the **False Positive Rate** as our fairness metric.\n",
    "\n",
    "What is the False Positive Rate in context? \n",
    "\n",
    "The False Positive group represents those individuals that should have gotten a loan, but were automatically denied.  Through a different lens, one could say these are people who deserved a loan but did not recieve it -- therefore, if our group had bias along the False Positive Rate dimension, that would mean one group was not recieving loans they deserved because of being in that group.\n",
    "\n",
    "For example, if the False Positive Rate was lower for Males than Females, that would mean the model is more likely predict an individual as defaulting because they are a woman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you need to install aequitas\n",
    "!pip install aequitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that is properly formatted for Aequitas\n",
    "aequitas = X_test.filter(items=[\"sex\",\"minority\"])\n",
    "aequitas[\"Sex\"] = aequitas[\"sex\"].apply(lambda x: \"M\" if x == 1 else \"F\")\n",
    "aequitas[\"Race\"] = aequitas[\"minority\"].apply(lambda x: \"Black\" if x == 1 else \"White\")\n",
    "aequitas[\"label_value\"] = y_test\n",
    "aequitas[\"score\"] = y_pred\n",
    "df = aequitas.drop(columns=['sex','minority'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attributes = ['Sex','Race']\n",
    "protected_groups = {'Sex':'F', 'Race':'Black'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_palette = sns.diverging_palette(225, 35, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sex = sns.countplot(x=\"Sex\", hue=\"score\", data=df[df.Sex.isin(['M', 'F'])], palette=aq_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_race = sns.countplot(x=\"Race\", hue=\"score\", data=df[df.Race.isin(['Black', 'White'])], palette=aq_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Group()\n",
    "xtab, _ = g.get_crosstabs(df)\n",
    "absolute_metrics = g.list_absolute_metrics(xtab)\n",
    "xtab[[col for col in xtab.columns if col not in absolute_metrics]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp = Plot()\n",
    "fpr = aqp.plot_group_metric(xtab, 'fpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Bias()\n",
    "bdf = b.get_disparity_predefined_groups(xtab, original_df=df, ref_groups_dict=protected_groups, alpha=0.05, mask_significance=True)\n",
    "calculated_disparities = b.list_disparities(bdf)\n",
    "disparity_significance = b.list_significance(bdf)\n",
    "bdf[['attribute_name', 'attribute_value'] +  calculated_disparities + disparity_significance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbdf = b.get_disparity_predefined_groups(xtab, original_df=df,\n",
    "                                         ref_groups_dict=protected_groups,\n",
    "                                         alpha=0.05,\n",
    "                                         mask_significance=False)\n",
    "\n",
    "# View disparity metrics added to dataframe\n",
    "majority_bdf = b.get_disparity_major_group(xtab, original_df=df, mask_significance=True)\n",
    "majority_bdf[['attribute_name', 'attribute_value'] +  calculated_disparities + disparity_significance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_metric_bdf = b.get_disparity_min_metric(df=xtab, original_df=df)\n",
    "# View disparity metrics added to dataframe\n",
    "min_metric_bdf[['attribute_name', 'attribute_value'] +  calculated_disparities + disparity_significance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp.plot_disparity(bdf, group_metric='fpr_disparity', attribute_name='Sex', significance_alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp.plot_disparity(bdf, group_metric='fpr_disparity', attribute_name='Race', significance_alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we will drop the variables Race and Sex and see how it affects bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1:  Drop sex and race from the model.\n",
    "X_train_new = X_train.drop(columns=['minority','sex'])\n",
    "X_test_new = X_test.drop(columns=['minority','sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "print(\"Penalty      C         Recall Score\")\n",
    "print(\"-----------------------------------\")\n",
    "best_recall = 0\n",
    "\n",
    "# Create the parameter grid and iterate through\n",
    "grid = [[x,y] for x in ['l1','l2'] for y in [1.00,0.10,0.01]]\n",
    "for Penalty,c in grid:    \n",
    "    \n",
    "    print(f\"{Penalty}           {c:.2f}      Training...\", end=\"\\r\")\n",
    "    \n",
    "    # Train a model with the current grid parameters and evaluate the recall score\n",
    "    temp_model = LogisticRegression(penalty=Penalty,C=c,solver='liblinear',random_state=142).fit(X_train_new,y_train)\n",
    "    temp_y_pred_proba = temp_model.predict_proba(X_test_new)[:,1]\n",
    "    temp_threshold = np.percentile(temp_y_pred_proba,75)\n",
    "    temp_y_pred = np.where(temp_y_pred_proba > temp_threshold, 1, 0)\n",
    "    temp_recall = recall_score(y_test,temp_y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"{Penalty}           {c:.2f}      {temp_recall}\")\n",
    "    \n",
    "    # If this is the best performing model, save the results\n",
    "    if temp_recall > best_recall:\n",
    "        best_recall = temp_recall\n",
    "        model_new = temp_model\n",
    "        y_pred_new = temp_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance\n",
    "# y_pred_proba_new = model_new.predict_proba(X_test_new)[:,1]\n",
    "# threshold = np.percentile(y_pred_proba_new,75)\n",
    "# y_pred_new = np.where(y_pred_proba > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect feature importance\n",
    "plt.barh(X_train_new.columns, model_new.coef_[0], color='b')\n",
    "plt.tight_layout(-10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerurn Aequitas\n",
    "aequitas = X_test.filter(items=[\"sex\",\"minority\"])\n",
    "aequitas[\"Sex\"] = aequitas[\"sex\"].apply(lambda x: \"M\" if x == 1 else \"F\")\n",
    "aequitas[\"Race\"] = aequitas[\"minority\"].apply(lambda x: \"Black\" if x == 1 else \"White\")\n",
    "aequitas[\"label_value\"] = y_test\n",
    "aequitas[\"score\"] = y_pred_new\n",
    "df = aequitas.drop(columns=['sex','minority'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_sex = sns.countplot(x=\"Sex\", hue=\"score\", data=df[df.Sex.isin(['M', 'F'])], palette=aq_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_race = sns.countplot(x=\"Race\", hue=\"score\", data=df[df.Race.isin(['Black', 'White'])], palette=aq_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Group()\n",
    "xtab, _ = g.get_crosstabs(df)\n",
    "absolute_metrics = g.list_absolute_metrics(xtab)\n",
    "xtab[[col for col in xtab.columns if col not in absolute_metrics]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp = Plot()\n",
    "fpr = aqp.plot_group_metric(xtab, 'fpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Bias()\n",
    "bdf = b.get_disparity_predefined_groups(xtab, original_df=df, ref_groups_dict=protected_groups, alpha=0.05, mask_significance=True)\n",
    "#calculated_disparities = b.list_disparities(bdf)\n",
    "#disparity_significance = b.list_significance(bdf)\n",
    "hbdf = b.get_disparity_predefined_groups(xtab, original_df=df,\n",
    "                                         ref_groups_dict=protected_groups,\n",
    "                                         alpha=0.05,\n",
    "                                         mask_significance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp.plot_disparity(bdf, group_metric='fpr_disparity', attribute_name='Sex', significance_alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqp.plot_disparity(bdf, group_metric='fpr_disparity', attribute_name='Race', significance_alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did dropping sex and minority have little, if any, affect on the bias in our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['MZ11CD_occupation'].corr(X_train['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['MZ11CD_occupation'].corr(X_train['minority'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**  Run the model again, but without occupation and/or zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of a robust bias mitigation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods of this analysis are based on the following paper: Rodolfa, K. T., Salomon, E., Haynes, L., Mendieta, I. H., Larson, J., & Ghani, R. (2020, January). Case study: predictive fairness to reduce misdemeanor recidivism through social service interventions. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 142-153). (https://arxiv.org/abs/2001.09233)\n",
    "\n",
    "A video summary of the paper can be found here: https://www.youtube.com/watch?v=K55bnPsvFOs\n",
    "\n",
    "An **in-depth tutorial** on bias mitigation can be found here:  https://www.youtube.com/watch?v=N67pE1AF5cM&list=PLUsfTziJs0NXL0KGEvAf8YU158yrG0JMr&index=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1:  The model \"as it is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "threshold = np.percentile(y_pred_proba,75)\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are used to evaluate whether or not an observation is\n",
    "#   a false positive, or true negative\n",
    "def label_fp(row,pred):\n",
    "    if (row[pred] == 1 and row['label'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def label_tn(row,pred):\n",
    "    if (row[pred] == 0 and row['label'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "# The following function wil calculate the false negative rate (FNR) of an observation\n",
    "def calculate_fpr(row):\n",
    "    return (row['fp']['sum'] / (row['fp']['sum'] + row['tn']['sum']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable dictionary\n",
    "# =====================\n",
    "#label = True value\n",
    "#score = Score [0,1] continuous\n",
    "#pred_k = Assigned risk group based on bias mitigation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = X_test.filter(items=[\"sex\",\"minority\"])\n",
    "df = X_test.copy()\n",
    "df[\"Group_x\"] = df[\"minority\"].apply(lambda x: \"Black\" if x == 1 else \"White\")\n",
    "df[\"label\"] = y_test\n",
    "df[\"score\"] = model.predict_proba(X_test)[:,1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.copy()\n",
    "# Calculate the risk outcome based on the score and the IEFP threshold\n",
    "temp['pred_k'] = temp.apply(lambda row: 1 if row['score'] >= threshold else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fp and tn for all rows\n",
    "temp['fp'] = temp.apply(lambda row: label_fp(row,'pred_k'), axis=1)\n",
    "temp['tn'] = temp.apply(lambda row: label_tn(row,'pred_k'), axis=1)\n",
    "# Count the number of predicted positives, fn, tp, and tn for each group\n",
    "temp_agg = temp.groupby('Group_x').agg({'Group_x': ['count'],'pred_k': ['sum'],'fp': ['sum'], 'tn': ['sum']})\n",
    "# Calculate the FPR for each group\n",
    "temp_agg['fpr'] = temp_agg.apply(calculate_fpr, axis=1)\n",
    "# Assign the FPR of the Black group as the reference\n",
    "ref_fpr = temp_agg.loc[temp_agg.index == 'Black']['fpr'][0]\n",
    "# Calculate the FPR parities of each group\n",
    "temp_agg['fpr_parity'] = temp_agg.apply(lambda row: row['fpr'] / ref_fpr, axis = 1 )\n",
    "temp_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model recall score\n",
    "print(recall_score(temp['label'], temp['pred_k']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(temp_agg.index), temp_agg['fpr'], width=0.4)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"FPR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 2:  Equalizing the Bias Metric for all Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, we attempt to equalize the FPRs of all grouprs.  This is done by shifting the order in which we select individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary which will store the assigned group sizes\n",
    "df_group_x = {\"Black\": None,\n",
    "             \"White\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the \"rolling fpr\"\n",
    "# The rolling fpr is the group FPR as the decision threshold is moved to include\n",
    "#   additional individuals\n",
    "def calc_rolling_fpr(row):\n",
    "    # Call on the global FP and TN variables\n",
    "    global fp\n",
    "    global tn\n",
    "    # If the observation is labeled 1, then we add 1 to the true positives\n",
    "    #   and we reduce the number of false negatives\n",
    "    if row['label'] == 0:\n",
    "        fp+=1\n",
    "        tn-=1\n",
    "    # If the label is not 1, then the FNR will not be affected\n",
    "    # Calculate the rolling FNR\n",
    "    fpr = (fp / (fp + tn))\n",
    "    return fpr\n",
    "\n",
    "# For each group, run the following algorithm\n",
    "for group in df_group_x:\n",
    "    # Create a temporary dataframe for the group\n",
    "    temp_df = df.loc[df['Group_x'] == group]\n",
    "    \n",
    "    # Debug: print the group and number of indivudals\n",
    "    print(f\"Calculating rolling FPR for group {group} containing {temp_df.shape[0]} individuals\")\n",
    "    \n",
    "    # Randomize the order of the dataframe so ties will be broken randomly\n",
    "    temp_df = temp_df.sample(frac=1).reset_index(drop=True)\n",
    "    # Sort the values by score in ascending order and reset the indext\n",
    "    temp_df = temp_df.sort_values(by=['score'], ascending=False)\n",
    "    temp_df = temp_df.reset_index(drop=True)\n",
    "\n",
    "    # Initialize the number of true negatives as the number of labeled negatives in the group\n",
    "    tn = temp_df['label'].value_counts()[0]\n",
    "    # Initiatlize the number of true positives as 0\n",
    "    fp = 0\n",
    "    # Calculate the rolling FNR for each group\n",
    "    temp_df['FPR_g_i'] = temp_df.apply(lambda row: calc_rolling_fpr(row), axis=1)\n",
    "    # Create a rolling count of each individual\n",
    "    temp_df['n_g_i'] = temp_df.index\n",
    "    # Store the group dataframe\n",
    "    df_group_x[group] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the group dataframes\n",
    "df_all_groups = pd.concat(list(df_group_x.values()))\n",
    "print(df_all_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by FPR ascending and the rolling count ascending\n",
    "df_all_groups = df_all_groups.sort_values(by=['FPR_g_i','n_g_i'],ascending=[True,True]).reset_index(drop=True)\n",
    "df_all_groups.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code contains the algorithm for equalizing the FPRs\n",
    "\n",
    "# x is the initial FNR threshold\n",
    "x = 0\n",
    "step_size = 0.13\n",
    "# k stores the final list sizes for each group\n",
    "k = {'Black': 0, 'White': 0}\n",
    "# K stores the final list size for all groups (it is the sum over k)\n",
    "K = 0\n",
    "# N is the final list size\n",
    "N = 39000\n",
    "\n",
    "# If desired, assign a maximum list size for each group\n",
    "max_list_size = {'White': None, 'Black': None}\n",
    "\n",
    "# Iteratre while the total list size is less than the desired list size\n",
    "while K < N:\n",
    "    # Begin by lowering the FNR threshold by a step of 0.01\n",
    "    x = x + step_size\n",
    "    \n",
    "    # For each group...\n",
    "    for i in df_all_groups.Group_x.unique():\n",
    "        # Check that the maximum list size for the group size has not been overstepped\n",
    "        if (max_list_size[i] == None) or (k[i] < max_list_size[i]):\n",
    "            # Let k be equal to the maximum individual count above the FNR threshold\n",
    "            k[i] = df_all_groups.loc[(df_all_groups['Group_x'] == i) & (df_all_groups['FPR_g_i'] < x)]['n_g_i'].max()\n",
    "    # Calculate k\n",
    "    K = sum(k.values())\n",
    "\n",
    "print(\"The final group sizes are:\")\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top k individuals from each group as high risk\n",
    "df_equal_fpr = df_all_groups\n",
    "df_equal_fpr['pred_k'] = df_all_groups.apply(lambda row: 1 if row['n_g_i'] < k[row['Group_x']] else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equal_fpr['pred_k'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_equal_fpr\n",
    "# Calculate the fp and tn for all rows\n",
    "temp['fp'] = temp.apply(lambda row: label_fp(row,'pred_k'), axis=1)\n",
    "temp['tn'] = temp.apply(lambda row: label_tn(row,'pred_k'), axis=1)\n",
    "# Count the number of predicted positives, fn, tp, and tn for each group\n",
    "temp_agg = temp.groupby('Group_x').agg({'Group_x': ['count'],'pred_k': ['sum'],'fp': ['sum'], 'tn': ['sum']})\n",
    "# Calculate the FPR for each group\n",
    "temp_agg['fpr'] = temp_agg.apply(calculate_fpr, axis=1)\n",
    "# Assign the FPR of the Black group as the reference\n",
    "ref_fpr = temp_agg.loc[temp_agg.index == 'Black']['fpr'][0]\n",
    "# Calculate the FPR parities of each group\n",
    "temp_agg['fpr_parity'] = temp_agg.apply(lambda row: row['fpr'] / ref_fpr, axis = 1 )\n",
    "temp_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(temp['label'], temp['pred_k']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the FNR for each group\n",
    "plt.bar(list(temp_agg.index), temp_agg['fpr'], width=0.4)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"FPR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** see how this mitigation affected gender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
